{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815dc680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'is', 'becoming', 'increasingly', 'popular', 'for', 'providing', 'business', 'solutions', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# loading en_core_web_sm and creating an nlp object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "text = \"NLP is becoming increasingly popular for providing business solutions.\"\n",
    "# Creating a Doc container for the text object\n",
    "doc = nlp(text)\n",
    "\n",
    "# Creating a list containing the text of each token in the Doc container\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eeb278",
   "metadata": {},
   "source": [
    "### spaCy NLP pipeline\n",
    "\n",
    "- Use `spacy.load()` to return nlp, a Language class\n",
    "- The Language object is the text processing pipeline\n",
    "- Apply `nlp()` on any text to get a `Doc` container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fee41b",
   "metadata": {},
   "source": [
    "### Container objects in spaCy\n",
    "- `Doc` - A container for accessing linguistic annotations of text\n",
    "- `Span` - A slice from a `Doc` object\n",
    "- `Token` - An individual token, i.e. a word, punctuation, whitespace, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03253908",
   "metadata": {},
   "source": [
    "### Pipeline components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a9980",
   "metadata": {},
   "source": [
    "- Tokenizer\n",
    "- Tagger\n",
    "- Lemmatizer\n",
    "- EntityRecognizer\n",
    "- Language\n",
    "- DependencyParser\n",
    "- Sentencizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc01ce",
   "metadata": {},
   "source": [
    "### Sentence segmentation\n",
    "\n",
    "- More complex than tokenization\n",
    "- Is a part of DependencyParser component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd77a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are learning NLP.\n",
      "This course introduces spaCy.\n"
     ]
    }
   ],
   "source": [
    "text = \"We are learning NLP. This course introduces spaCy.\"\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd562a07",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728a056",
   "metadata": {},
   "source": [
    "- A lemma is a base form of a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535218fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'we'), ('are', 'be'), ('seeing', 'see'), ('her', 'she'), ('after', 'after'), ('one', 'one'), ('year', 'year'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('We are seeing her after one year.')\n",
    "print([(token.text, token.lemma_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe2890",
   "metadata": {},
   "source": [
    "### Linguistic features in spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2acdc",
   "metadata": {},
   "source": [
    "#### POS tagging \n",
    "- Categorizing words grammatically, based on function and context within a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f04ebc",
   "metadata": {},
   "source": [
    "- Named Entity Recognition\n",
    "\n",
    "A named entity is a word or phrase that refers to a specific entity with a name\n",
    "Named-entity recognition (NER) classifies named entities into pre-defined categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5d058",
   "metadata": {},
   "source": [
    "### displaCy\n",
    "\n",
    "- The displaCy entity visualizer highlights named entities and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551a73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:108: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Albert Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was genius.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "text = 'Albert Einstein was genius.'\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93818e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Albert Einstein\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was genius.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf9b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['What is the arrival time in San francisco for the 7:55 AM flight leaving Washington?',\n",
    " 'Cheapest airfare from Tacoma to Orlando is 650 dollars.',\n",
    " 'Round trip fares from Pittsburgh to Philadelphia are under 1000 dollars!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08a19c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  What | POS tag:  PRON | POS explaination:  pronoun\n",
      "\n",
      "\n",
      "text:  is | POS tag:  AUX | POS explaination:  auxiliary\n",
      "\n",
      "\n",
      "text:  the | POS tag:  DET | POS explaination:  determiner\n",
      "\n",
      "\n",
      "text:  arrival | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  time | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  in | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  San | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  francisco | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  for | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  the | POS tag:  DET | POS explaination:  determiner\n",
      "\n",
      "\n",
      "text:  7:55 | POS tag:  NUM | POS explaination:  numeral\n",
      "\n",
      "\n",
      "text:  AM | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  flight | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  leaving | POS tag:  VERB | POS explaination:  verb\n",
      "\n",
      "\n",
      "text:  Washington | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  ? | POS tag:  PUNCT | POS explaination:  punctuation\n",
      "\n",
      "\n",
      "text:  Cheapest | POS tag:  ADJ | POS explaination:  adjective\n",
      "\n",
      "\n",
      "text:  airfare | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  from | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  Tacoma | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  to | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  Orlando | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  is | POS tag:  AUX | POS explaination:  auxiliary\n",
      "\n",
      "\n",
      "text:  650 | POS tag:  NUM | POS explaination:  numeral\n",
      "\n",
      "\n",
      "text:  dollars | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  . | POS tag:  PUNCT | POS explaination:  punctuation\n",
      "\n",
      "\n",
      "text:  Round | POS tag:  ADJ | POS explaination:  adjective\n",
      "\n",
      "\n",
      "text:  trip | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  fares | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  from | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  Pittsburgh | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  to | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  Philadelphia | POS tag:  PROPN | POS explaination:  proper noun\n",
      "\n",
      "\n",
      "text:  are | POS tag:  AUX | POS explaination:  auxiliary\n",
      "\n",
      "\n",
      "text:  under | POS tag:  ADP | POS explaination:  adposition\n",
      "\n",
      "\n",
      "text:  1000 | POS tag:  NUM | POS explaination:  numeral\n",
      "\n",
      "\n",
      "text:  dollars | POS tag:  NOUN | POS explaination:  noun\n",
      "\n",
      "\n",
      "text:  ! | POS tag:  PUNCT | POS explaination:  punctuation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### POS tagging\n",
    "\n",
    "documents = [nlp(text) for text in texts]\n",
    "\n",
    "for doc in documents:\n",
    "    for token in doc:\n",
    "        print(\"text: \", token.text, \"| POS tag: \", token.pos_, \"| POS explaination: \", spacy.explain(token.pos_))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d720c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('San francisco', 'GPE'), ('7:55 AM', 'TIME'), ('Washington', 'GPE')]\n",
      "[('Tacoma', 'GPE'), ('Orlando', 'GPE'), ('650 dollars', 'MONEY')]\n",
      "[('Pittsburgh', 'GPE'), ('Philadelphia', 'GPE')]\n",
      "\n",
      "text: Orlando | Entity type:  GPE\n"
     ]
    }
   ],
   "source": [
    "## Using tokens\n",
    "\n",
    "documents = [nlp(text) for text in texts]\n",
    "\n",
    "for doc in documents:\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "    \n",
    "print(\"\\ntext:\", documents[1][5].text, \"| Entity type: \", documents[1][5].ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7152739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in documents:\n",
      " [1, 1, 1] \n",
      "\n",
      "Third text entities:\n",
      " [('Pittsburgh', 'GPE'), ('Philadelphia', 'GPE')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store sentences of each Doc container in documents\n",
    "sentences = [[sent for sent in doc.sents] for doc in documents]\n",
    "\n",
    "# Create a list to track number of sentences per Doc container in documents\n",
    "num_sentences = [len([sent for sent in doc.sents]) for doc in documents]\n",
    "print(\"Number of sentences in documents:\\n\", num_sentences, \"\\n\")\n",
    "\n",
    "# Record entities text and corresponding label of the third Doc container\n",
    "third_text_entities = [(ent.text, ent.label_) for ent in documents[2].ents]\n",
    "\n",
    "print(\"Third text entities:\\n\", third_text_entities, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bf596",
   "metadata": {},
   "source": [
    "### Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
